{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c918c499",
   "metadata": {},
   "source": [
    "# Second practical exercise: Grid World and Value iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8627d33",
   "metadata": {},
   "source": [
    "Repo: https://github.com/KRLGroup/RL_2025.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fca4cd",
   "metadata": {},
   "source": [
    "# A deterministic grid world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fc996",
   "metadata": {},
   "source": [
    "Finite grid with some obstacles inside. The agent can move up, left, right and down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57edf28d",
   "metadata": {},
   "source": [
    "![](imgs/grid_world.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7541675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /home/xpsfede/miniconda3/envs/RL/lib/python3.8/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/xpsfede/miniconda3/envs/RL/lib/python3.8/site-packages (from gymnasium) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/xpsfede/miniconda3/envs/RL/lib/python3.8/site-packages (from gymnasium) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/xpsfede/miniconda3/envs/RL/lib/python3.8/site-packages (from gymnasium) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/xpsfede/miniconda3/envs/RL/lib/python3.8/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/xpsfede/miniconda3/envs/RL/lib/python3.8/site-packages (from gymnasium) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/xpsfede/miniconda3/envs/RL/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fb2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c0423ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom 2d grid world enviroment\n",
    "class GridWorld(gym.Env):\n",
    "    metadata = {'render.modes': ['console']}\n",
    "\n",
    "    \n",
    "    # actions available\n",
    "    UP = 0\n",
    "    LEFT = 1\n",
    "    DOWN = 2\n",
    "    RIGHT = 3\n",
    "\n",
    "\n",
    "    def __init__(self, width, height):\n",
    "        super(GridWorld, self).__init__()\n",
    "        self.ACTION_NAMES = [\"UP\", \"LEFT\", \"DOWN\", \"RIGHT\"]\n",
    "        self.num_actions = 4\n",
    "\n",
    "        self.size = width * height  # size of the grid world\n",
    "        self.num_states = self.size\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_obstacles = int((width+height)/2)\n",
    "        self.end_state = np.array([random.randrange(height) , random.randrange(width)], dtype=np.uint8) # goal state = bottom right cell\n",
    "        \n",
    "        while self.end_state[0] == 0 and self.end_state[1] == 0:\n",
    "                self.end_state = np.array([random.randrange(height) , random.randrange(width)], dtype=np.uint8)\n",
    "    \n",
    "        \n",
    "\n",
    "        # actions of agents : up, down, left and right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # observation : cell indices in the grid\n",
    "        self.observation_space = spaces.MultiDiscrete([self.height, self.width])\n",
    "\n",
    "        self.obstacles = np.zeros((height, width))\n",
    "\n",
    "        for i in range(self.num_obstacles):\n",
    "            obstacle = random.randrange(height) , random.randrange(width)\n",
    "            while obstacle in [(0, 0),tuple(self.end_state)]:\n",
    "                obstacle = random.randrange(height), random.randrange(width)\n",
    "            self.obstacles[obstacle] = 1\n",
    "\n",
    "        self.num_steps = 0\n",
    "        self.max_steps = height*width\n",
    "\n",
    "        self.current_state = np.zeros((2), np.uint8)#init state = [0,0]\n",
    "\n",
    "        self.directions = np.array([\n",
    "            [-1,0], #UP\n",
    "            [0,-1], #LEFT\n",
    "            [1,0], #DOWN\n",
    "            [0,1] #RIGHT\n",
    "        ])\n",
    "        \n",
    "    def step(self, action):\n",
    "        s_prime = self.transition_function(self.current_state, action)\n",
    "        reward = self.reward_function(s_prime)\n",
    "        terminated, truncated = self.termination_condition(s_prime)\n",
    "\n",
    "        self.current_state = s_prime\n",
    "        self.num_steps += 1\n",
    "\n",
    "        return self.current_state, reward, terminated, truncated, None\n",
    "    \n",
    "    \n",
    "    def transition_function(self, s, a): # TODO\n",
    "        \n",
    "        # Q1\n",
    "        # (a) -----------------------------------------\n",
    "        # s_prime = s + a\n",
    "        # if (s_prime < 0).any(): return s\n",
    "        # if s_prime[0] >= self.width: return s    \n",
    "        # if s_prime[1] >= self.height: return s \n",
    "        # if self.obstacles[s_prime[0], s_prime[1]] == 1: return s\n",
    "        \n",
    "        # (b) -----------------------------------------\n",
    "        # s_prime = s + self.directions[a]\n",
    "        # if (s_prime < 0).any(): return s_prime\n",
    "        # if s_prime[0] <= self.height: return s  \n",
    "        # if s_prime[1] <= self.width: return s \n",
    "        # if self.obstacles[s_prime[0], s_prime[1]] == 1: return s\n",
    "        \n",
    "        # (c) -----------------------------------------\n",
    "        s_prime = s + self.directions[a]\n",
    "        if (s_prime < 0).any(): return s\n",
    "        if s_prime[0] >= self.height: return s\n",
    "        if s_prime[1] >= self.width: return s\n",
    "        if self.obstacles[s_prime[0], s_prime[1]] == 1: return s\n",
    "        \n",
    "        \n",
    "        return s_prime\n",
    "\n",
    "    \n",
    "    def reward_function(self,s): # TODO\n",
    "        \n",
    "        # Q2\n",
    "        # (a) -----------------------------------------\n",
    "        # r = 0\n",
    "        # if (s != self.end_state).all():\n",
    "        #     r = 1\n",
    "\n",
    "        # (b) -----------------------------------------\n",
    "        r = 0\n",
    "        if (s == self.end_state).all():\n",
    "            r = 1\n",
    "\n",
    "        # (c) -----------------------------------------\n",
    "        # r = 1               \n",
    "        # if (s == self.end_state).all():\n",
    "        #     r = 0             \n",
    "\n",
    "        return r\n",
    "\n",
    "    def termination_condition(self, s):\n",
    "        truncated = False\n",
    "        terminated = False\n",
    "\n",
    "        # Q3\n",
    "        # (a)\n",
    "        truncated = self.num_steps >= self.max_steps\n",
    "        # (b) \n",
    "        # truncated = self.num_steps <= self.max_steps\n",
    "        # (c) \n",
    "        # truncated = self.num_steps > 5\n",
    "        #-----------------------------------------------------\n",
    "\n",
    "        # Q4\n",
    "        # (a) \n",
    "        # terminated = (s != self.end_state).any() \n",
    "        # (b) \n",
    "        # terminated = (s == self.end_state).any()\n",
    "        # (c) \n",
    "        terminated = (s == self.end_state).all()\n",
    "\n",
    "        return terminated, truncated\n",
    "    \n",
    "    def transition_probabilities(self, s, a):\n",
    "        prob_next_state = np.zeros((self.height, self.width))\n",
    "        s_prime = self.transition_function(s, a)\n",
    "\n",
    "        prob_next_state[s_prime[0], s_prime[1]] = 1.0\n",
    "\n",
    "        return prob_next_state#.flatten()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_state = np.zeros((2), np.uint8)\n",
    "        self.num_steps = 0\n",
    "\n",
    "        return self.current_state\n",
    "    \n",
    "    def reward_probabilities(self):\n",
    "        rewards = np.zeros((self.num_states))\n",
    "        i = 0\n",
    "        for r in range(self.height):\n",
    "            for c in range(self.width):\n",
    "                state = np.array([r,c], dtype=np.uint8)\n",
    "                rewards[i] = self.reward_function(state)\n",
    "                i+=1\n",
    "\n",
    "        return rewards\n",
    "    \n",
    "    def render(self):\n",
    "        '''\n",
    "            render the state\n",
    "        '''\n",
    "\n",
    "        row = self.current_state[0]\n",
    "        col = self.current_state[1]\n",
    "\n",
    "        for r in range(self.height):\n",
    "            for c in range(self.width):\n",
    "                if r == row and c == col:\n",
    "                    print(\"| A \", end='')\n",
    "                elif r == self.end_state[0] and c == self.end_state[1]:\n",
    "                    print(\"| G \", end='')\n",
    "                else:\n",
    "                    if self.obstacles[r,c] == 1:\n",
    "                        print('|///', end='')\n",
    "                    else:\n",
    "                        print('|___', end='')\n",
    "            print('|')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b573a8",
   "metadata": {},
   "source": [
    "Simulate all the four actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed5bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| A |___|///|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___| G |___|\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|///|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___| G |___|\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |___|///|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___| G |___|\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|///|\n",
      "| A |///|///|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___| G |___|\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___|///|\n",
      "| A |///|///|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___| G |___|\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld(3,5)\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "action_sequence = [0,1,2,3]\n",
    "\n",
    "for a in action_sequence:\n",
    "    print(env.ACTION_NAMES[a])\n",
    "    env.step(a)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4998a26",
   "metadata": {},
   "source": [
    "Simulate a random episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63f0500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___| A |\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___| A |\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___|___| A |\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___|___| A |\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "env.reset()\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    print(env.ACTION_NAMES[action])\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55b2b3",
   "metadata": {},
   "source": [
    "## A non deterministic grid world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7d325",
   "metadata": {},
   "source": [
    "The agent goes with probability p to the right cell, with probability 1 - p in a different cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbfb3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonDeterministicGridWorld(GridWorld):\n",
    "    def __init__(self, width, height, p=0.8):\n",
    "        super(NonDeterministicGridWorld, self).__init__(width, height)\n",
    "        self.probability_right_action = p\n",
    "\n",
    "    def transition_function(self, s, a):\n",
    "        s_prime = s + self.directions[a, :]\n",
    "\n",
    "        #with probability 1 - p diagonal movement\n",
    "        if random.random() <= 1 - self.probability_right_action:\n",
    "            if random.random() < 0.5:\n",
    "                s_prime = s_prime + self.directions[(a+1)%self.num_actions, :]\n",
    "            else:\n",
    "                s_prime = s_prime + self.directions[(a-1)%self.num_actions, :]\n",
    "\n",
    "\n",
    "        if s_prime[0] < self.height and s_prime[1] < self.width and (s_prime >= 0).all():\n",
    "            if self.obstacles[s_prime[0], s_prime[1]] == 0 :\n",
    "                return s_prime\n",
    "\n",
    "        return s\n",
    "\n",
    "    def transition_probabilities(self, s, a):\n",
    "        cells = []\n",
    "        probs = []\n",
    "        prob_next_state = np.zeros((self.height, self.width))\n",
    "        s_prime_right =  s + self.directions[a, :]\n",
    "        if s_prime_right[0] < self.height and s_prime_right[1] < self.width and (s_prime_right >= 0).all():\n",
    "            if self.obstacles[s_prime_right[0], s_prime_right[1]] == 0 :\n",
    "                prob_next_state[s_prime_right[0], s_prime_right[1]] = self.probability_right_action\n",
    "                cells.append(s_prime_right)\n",
    "                probs.append(self.probability_right_action)\n",
    "\n",
    "        s_prime = s_prime_right + self.directions[(a + 1) % self.num_actions, :]\n",
    "        if s_prime[0] < self.height and s_prime[1] < self.width and (s_prime >= 0).all():\n",
    "            if self.obstacles[s_prime[0], s_prime[1]] == 0 :\n",
    "                prob_next_state[s_prime[0], s_prime[1]] = (1 - self.probability_right_action) / 2\n",
    "                cells.append(s_prime.copy())\n",
    "                probs.append((1 - self.probability_right_action) / 2)\n",
    "\n",
    "        s_prime = s_prime_right + self.directions[(a - 1) % self.num_actions, :]\n",
    "        if s_prime[0] < self.height and s_prime[1] < self.width and (s_prime >= 0).all():\n",
    "            if self.obstacles[s_prime[0], s_prime[1]] == 0 :\n",
    "                prob_next_state[s_prime[0], s_prime[1]] = (1 - self.probability_right_action) / 2\n",
    "                cells.append(s_prime.copy())\n",
    "                probs.append((1 - self.probability_right_action) / 2)\n",
    "\n",
    "        #normalization\n",
    "        sump = sum(probs)\n",
    "        #for cell in cells:\n",
    "        #    prob_next_state[cell[0], cell[1]] /= sump\n",
    "        prob_next_state[s[0], s[1]] = 1 - sump\n",
    "        return prob_next_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccd6e7",
   "metadata": {},
   "source": [
    "Simulate a random episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad16ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| A | G |___|\n",
      "|///|___|___|\n",
      "|___|___|___|\n",
      "|///|///|___|\n",
      "|___|___|___|\n",
      "\n",
      "\n",
      "[[0.9 0.  0. ]\n",
      " [0.  0.1 0. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]]\n",
      "\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "env = NonDeterministicGridWorld(3,5)\n",
    "state = env.reset()\n",
    "env.render()\n",
    "#next state if we start from state 0,0 and we do action down\n",
    "next_state_prob = env.transition_probabilities(state, 2)\n",
    "print(next_state_prob)\n",
    "print()\n",
    "print(env.reward_probabilities())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5823a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWN\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|///|___| G |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    print(env.ACTION_NAMES[action])\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33758b3e",
   "metadata": {},
   "source": [
    "VALUE ITERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17837d79",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7efca",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83617227",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379abfa",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5b9af",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5bc10",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10fa025",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b096193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=0.99, iters=100):\n",
    "    #initialize values\n",
    "    values = np.zeros((env.num_states))\n",
    "    best_actions = np.zeros((env.num_states), dtype=int)\n",
    "    STATES = np.zeros((env.num_states, 2), dtype=np.uint8)\n",
    "    REWARDS = env.reward_probabilities()\n",
    "    print(REWARDS)\n",
    "    i = 0\n",
    "    for r in range(env.height):\n",
    "        for c in range(env.width):\n",
    "            state = np.array([r, c], dtype=np.uint8)\n",
    "            STATES[i] = state\n",
    "            i += 1\n",
    "    \n",
    "    for i in range(iters):\n",
    "        v_old = values.copy()\n",
    "        for s in range(env.num_states):\n",
    "            state = STATES[s]\n",
    "\n",
    "            if (state == env.end_state).all() or i >= env.max_steps or env.obstacles[state[0],state[1]]:\n",
    "                continue # if we reach the termination condition, we cannot perform any action\n",
    "\n",
    "\n",
    "            max_va = -np.inf\n",
    "            best_a = 0\n",
    "            for a in range(env.num_actions):\n",
    "                next_state_prob = env.transition_probabilities(state, a).flatten()\n",
    "\n",
    "                #Q5\n",
    "                # (a)\n",
    "                # va = (next_state_prob*(REWARDS + gamma*values)).sum()\n",
    "                # (b) \n",
    "                # va = (REWARDS + gamma*v_old).sum()\n",
    "                # (c) \n",
    "                va = (next_state_prob*(REWARDS + gamma*v_old)).sum()\n",
    "                \n",
    "                #Q6\n",
    "                # (a) \n",
    "                if va > max_va:\n",
    "                    max_va = va\n",
    "                    best_a = a\n",
    "                # (b) \n",
    "                # if va < max_va:\n",
    "                    # max_va = a\n",
    "                    # best_a = va\n",
    "                # (c) \n",
    "                # if va > values:\n",
    "                    # max_va = va\n",
    "                    # best_a = a\n",
    "\n",
    "            values[s] = max_va\n",
    "            best_actions[s] = best_a\n",
    "\n",
    "    return values.reshape((env.height, env.width)), best_actions.reshape((env.height, env.width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e42916",
   "metadata": {},
   "source": [
    "estimate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3420f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.9853438  0.99750623 0.        ]\n",
      " [0.97770444 0.98757397 0.99750623]\n",
      " [0.96793754 0.         0.9853438 ]\n",
      " [0.95586771 0.96336863 0.97305769]\n",
      " [0.         0.         0.961193  ]]\n",
      "[[3 3 0]\n",
      " [3 0 0]\n",
      " [0 0 0]\n",
      " [0 3 0]\n",
      " [0 0 0]]\n",
      "| A |___| G |\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///|___|\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = NonDeterministicGridWorld(3,5)\n",
    "values, best_actions = value_iteration(env, iters=100)\n",
    "\n",
    "print(values)\n",
    "print(best_actions)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77687aaf",
   "metadata": {},
   "source": [
    "simulate optimal policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2536107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: RIGHT\n",
      "| A |___| G |\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///|___|\n",
      "\n",
      "\n",
      "Action: RIGHT\n",
      "| A |___| G |\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///|___|\n",
      "\n",
      "\n",
      "Action: RIGHT\n",
      "|___| A | G |\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///|___|\n",
      "\n",
      "\n",
      "Action: RIGHT\n",
      "|___|___| A |\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///|___|\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "while not done:\n",
    "    action = best_actions[state[0],state[1]]\n",
    "    print(\"Action:\",env.ACTION_NAMES[action])\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
